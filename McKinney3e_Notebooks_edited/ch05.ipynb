{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Chapter 4: Getting Started with Pandas<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#5.1-Introduction-to-pandas-Data-Structures\" data-toc-modified-id=\"5.1-Introduction-to-pandas-Data-Structures-1\">5.1 Introduction to pandas Data Structures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series\" data-toc-modified-id=\"Series-1.1\">Series</a></span></li><li><span><a href=\"#DataFrame\" data-toc-modified-id=\"DataFrame-1.2\">DataFrame</a></span></li><li><span><a href=\"#Index-Objects\" data-toc-modified-id=\"Index-Objects-1.3\">Index Objects</a></span></li></ul></li><li><span><a href=\"#5.2-Essential-Functionality\" data-toc-modified-id=\"5.2-Essential-Functionality-2\">5.2 Essential Functionality</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reindexing\" data-toc-modified-id=\"Reindexing-2.1\">Reindexing</a></span></li><li><span><a href=\"#Dropping-Entries-from-an-Axis\" data-toc-modified-id=\"Dropping-Entries-from-an-Axis-2.2\">Dropping Entries from an Axis</a></span></li><li><span><a href=\"#Indexing,-Selection,-and-Filtering\" data-toc-modified-id=\"Indexing,-Selection,-and-Filtering-2.3\">Indexing, Selection, and Filtering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Selection-on-DataFrame-with-loc-and-iloc\" data-toc-modified-id=\"Selection-on-DataFrame-with-loc-and-iloc-2.3.1\">Selection on DataFrame with loc and iloc</a></span></li><li><span><a href=\"#Integer-indexing-pitfalls\" data-toc-modified-id=\"Integer-indexing-pitfalls-2.3.2\">Integer indexing pitfalls</a></span></li><li><span><a href=\"#Pitfalls-with-chained-indexing`\" data-toc-modified-id=\"Pitfalls-with-chained-indexing`-2.3.3\">Pitfalls with chained indexing`</a></span></li></ul></li><li><span><a href=\"#Arithmetic-and-Data-Alignment\" data-toc-modified-id=\"Arithmetic-and-Data-Alignment-2.4\">Arithmetic and Data Alignment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Arithmetic-methods-with-fill-values\" data-toc-modified-id=\"Arithmetic-methods-with-fill-values-2.4.1\">Arithmetic methods with fill values</a></span></li><li><span><a href=\"#Operations-between-DataFrame-and-Series\" data-toc-modified-id=\"Operations-between-DataFrame-and-Series-2.4.2\">Operations between DataFrame and Series</a></span></li></ul></li><li><span><a href=\"#Function-Application-and-Mapping\" data-toc-modified-id=\"Function-Application-and-Mapping-2.5\">Function Application and Mapping</a></span></li><li><span><a href=\"#Sorting-and-Ranking\" data-toc-modified-id=\"Sorting-and-Ranking-2.6\">Sorting and Ranking</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sorting\" data-toc-modified-id=\"Sorting-2.6.1\">Sorting</a></span></li><li><span><a href=\"#Ranking\" data-toc-modified-id=\"Ranking-2.6.2\">Ranking</a></span></li></ul></li><li><span><a href=\"#Axis-Indexes-with-Duplicate-Labels\" data-toc-modified-id=\"Axis-Indexes-with-Duplicate-Labels-2.7\">Axis Indexes with Duplicate Labels</a></span></li></ul></li><li><span><a href=\"#5.3-Summarizing-and-Computing-Descriptive-Statistics\" data-toc-modified-id=\"5.3-Summarizing-and-Computing-Descriptive-Statistics-3\">5.3 Summarizing and Computing Descriptive Statistics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Correlation-and-Covariance\" data-toc-modified-id=\"Correlation-and-Covariance-3.1\">Correlation and Covariance</a></span></li><li><span><a href=\"#Unique-Values,-Value-Counts,-and-Membership\" data-toc-modified-id=\"Unique-Values,-Value-Counts,-and-Membership-3.2\">Unique Values, Value Counts, and Membership</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use Colab Notebook, you can uncomment the following to mount your Google Drive to Colab\n",
    "# After that, your colab notebook can read/write files and data in your Google Drive\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use Colab Notebook, please change the current directory to be the folder that you save \n",
    "# your Notebook and data folder for example, I save my Colab files and data in the following location\n",
    "\n",
    "#%cd /content/drive/MyDrive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries and modules, and define default setting for the notebook\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(12345)\n",
    "\n",
    "import pandas as pd # https://pandas.pydata.org/  Check the documentation there\n",
    "from pandas import Series, DataFrame # import modules into the local namespace if they are frequently used\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "PREVIOUS_MAX_ROWS = pd.options.display.max_rows\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_colwidth = 80\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Introduction to pandas Data Structures\n",
    "\n",
    "pandas will be a major tool of interest throughout much of the rest of the book. It\n",
    "contains data structures and data manipulation tools designed to make data cleaning\n",
    "and analysis fast and convenient in Python.\n",
    "\n",
    "While pandas adopts many coding idioms from NumPy, the biggestabout difference\n",
    "is that pandas is designed for working with tabular or heterogeneous data. NumPy, by\n",
    "contrast, is best suited for working with homogeneously typed numerical array data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "A Series is a one-dimensional array-like object containing a sequence of values (of\n",
    "similar types to NumPy types) of the same type and an associated array of data labels,\n",
    "called its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Series shows the index on the left and the values on the right. \n",
    "# If the index object is not explicitly specififed, 0 to n-1 is used \n",
    "#where n is the number of elements in the Series\n",
    "\n",
    "obj = pd.Series([4, 7, -5, 3])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get the array representation the Series via its array and index attributes\n",
    "obj.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can get the index object the Series via its array and index attributes\n",
    "obj.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create a Series with an index identifying each data point with a label:\n",
    "\n",
    "obj2 = pd.Series([4, 7, -5, 3], index=[\"d\", \"b\", \"a\", \"c\"])\n",
    "print(obj2)\n",
    "obj2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use labels in the index when selecting single values or a set of values\n",
    "\n",
    "obj2[\"a\"]\n",
    "obj2[\"d\"] = 6\n",
    "obj2[[\"c\", \"a\", \"d\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering a Series with a Boolean array\n",
    "\n",
    "obj2[obj2 > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar multiplication\n",
    "obj2 * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math functions\n",
    "np.exp(obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Series can be seen as a fixed-length, ordered dictionary, \n",
    "# as it is a mapping of index values to data values. \n",
    "# It can be used in many contexts where you might use a dictionary\n",
    "\n",
    "\"b\" in obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"e\" in obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have data contained in a Python dictionary, we can create a Series from\n",
    "# it by passing the dictionary:\n",
    "\n",
    "sdata = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}\n",
    "obj3 = pd.Series(sdata)\n",
    "obj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Series back to dictionary using the method to_dict()\n",
    "# When we are only passing a dictionary, the index in the resulting Series will respect\n",
    "# the order of the keys according to the dictionary’s keys method, which depends on\n",
    "# the key insertion order:\n",
    "\n",
    "obj3.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can override this by passing an index with the dictionary keys in the order \n",
    "# we want them to appear in the resulting Series:\n",
    "\n",
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]\n",
    "obj4 = pd.Series(sdata, index=states)\n",
    "obj4\n",
    "\n",
    "\n",
    "# Here, three values found in sdata were placed in the appropriate locations, \n",
    "# but since no value for \"California\" was found, it appears as NaN (Not a Number), \n",
    "# which is considered in pandas to mark missing or NA values.\n",
    "# Since \"Utah\" was not included in states, it is excluded from the resulting object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The isna function in pandas is used to detect missing data\n",
    "\n",
    "pd.isna(obj4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notna function in pandas is used to detect non-missing (not an NA) data\n",
    "\n",
    "pd.notna(obj4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series also has these as instance methods\n",
    "\n",
    "obj4.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A useful Series feature is that it automatically aligns by index label in arithmetic operations\n",
    "\n",
    "print(obj3,'\\n')\n",
    "\n",
    "print(obj4,'\\n')\n",
    "\n",
    "obj3 + obj4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both the Series object itself and its index have a name attribute, \n",
    "# which integrates with other areas of pandas functionality:\n",
    "\n",
    "obj4.name = \"population\"\n",
    "obj4.index.name = \"state\"\n",
    "obj4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj =pd.Series([4,7,-5,3])\n",
    "print(obj,'\\n')\n",
    "\n",
    "# A Series’s index can be altered in place by assignment\n",
    "obj.index = [\"Bob\", \"Steve\", \"Jeff\", \"Ryan\"]\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "A DataFrame represents a rectangular table of data and contains an ordered, named\n",
    "collection of columns, each of which can be a different value type (numeric, string,\n",
    "Boolean, etc.). The DataFrame has both a row and column index; it can be thought of\n",
    "as a dictionary of Series all sharing the same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is defined as a library\n",
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n",
    "        \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "\n",
    "# covert data into DataFrame using the method pandas.DataFrame()\n",
    "frame = pd.DataFrame(data)\n",
    "\n",
    "# The resulting DataFrame will have its index assigned automatically, as with Series,\n",
    "# and the columns are placed according to the order of the keys in data\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the head method selects only the first five rows\n",
    "\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tail method selects only the last five rows\n",
    "\n",
    "frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we specify a sequence of columns, the DataFrame’s columns will be arranged in that order\n",
    "\n",
    "pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we pass a column that isn’t contained in the dictionary, it will appear with missing\n",
    "#values in the result:\n",
    "\n",
    "frame2 = pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\", \"debt\"])\n",
    "print(frame2,'\\n'),\n",
    "frame2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A column in a DataFrame can be retrieved as a Seriesby dictionary-like notation\n",
    "\n",
    "frame2[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A column in a DataFrame can also be retrieved as a Series by using the .attribute notation\n",
    "\n",
    "frame2.year\n",
    "\n",
    "\n",
    "#frame2[column] works for any column name, but frame2.column works only when the column name \n",
    "# is a valid Python variable name and does not conflict with any of the method names in DataFrame.\n",
    "# For example, if a column’s name contains whitespace or symbols other than underscores, \n",
    "# it cannot be accessed with the dot attribute method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame2,'\\n')\n",
    "\n",
    "# Rows can also be retrieved by position or name with the special iloc and loc attributes\n",
    "\n",
    "frame2.loc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows can also be retrieved by position or name with the special iloc and loc attributes\n",
    "# iloc can only take integer arguments, whereas loc usually takes label indexing\n",
    "\n",
    "frame2.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns can be modified by assignment\n",
    "\n",
    "frame2[\"debt\"] = 16.5\n",
    "frame2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2[\"debt\"] = np.arange(6.)\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we assign lists or arrays to a column, the value’s length must match the\n",
    "# length of the DataFrame. \n",
    "# If you assign a Series, its labels will be realigned exactly to\n",
    "#the DataFrame’s index, inserting missing values in any index values not present\n",
    "\n",
    "val = pd.Series([-1.2, -1.5, -1.7], index=[\"two\", \"four\", \"five\"])\n",
    "print(val,'\\n')\n",
    "\n",
    "frame2[\"debt\"] = val\n",
    "frame2\n",
    "\n",
    "# indices of val have no overlap with the indices of frame2. Therefore, elements of \n",
    "# val are not assigned to frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series([-1.2, -1.5, -1.7], index=[2, 4, 5])\n",
    "print(val,'\\n')\n",
    "\n",
    "# indices of val have partial overlap with the indices of frame2. Therefore, the assignment \n",
    "# changes frame2\n",
    "\n",
    "frame2[\"debt\"] = val\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column named \"eestern\", which is a new column of Boolean values where the state column equals \"Ohio\":\n",
    "\n",
    "frame2[\"eastern\"] = frame2[\"state\"] == \"Ohio\"\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the del method to delete a column\n",
    "\n",
    "del frame2[\"eastern\"]\n",
    "frame2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another common form of data is a nested dictionary of dictionaries\n",
    "\n",
    "populations = {\"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6},\n",
    "               \"Nevada\": {2001: 2.4, 2002: 2.9}}\n",
    "\n",
    "# If the nested dictionary is passed to the DataFrame, pandas will interpret the outer\n",
    "# dictionary keys as the columns, and the inner keys as the row indices\n",
    "frame3 = pd.DataFrame(populations)\n",
    "frame3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can transpose the DataFrame (swap rows and columns) with similar syntax to a NumPy array\n",
    "\n",
    "frame3.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keys in the inner dictionaries are combined to form the index in the result. This\n",
    "# isn’t true if an explicit index is specified. \n",
    "\n",
    "# In this example, an explicit index is specified\n",
    "\n",
    "pd.DataFrame(populations, index=[2001, 2002, 2003])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries of Series are treated in much the same way\n",
    "\n",
    "pdata = {\"Ohio\": frame3[\"Ohio\"][:-1],\n",
    "         \"Nevada\": frame3[\"Nevada\"][:2]}\n",
    "pd.DataFrame(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a DataFrame’s index and columns have their name attributes set, these will also be displayed\n",
    "\n",
    "frame3.index.name = \"year\"\n",
    "frame3.columns.name = \"state\"\n",
    "frame3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike Series, DataFrame does not have a name attribute. DataFrame’s to_numpy\n",
    "# method returns the data contained in the DataFrame as a two-dimensional ndarray\n",
    "\n",
    "frame3.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the DataFrame’s columns are different data types, the data type of the returned\n",
    "# array will be chosen to accommodate all of the columns\n",
    "\n",
    "frame2.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Objects\n",
    "\n",
    "Table 5-2. Some Index methods and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas’s Index objects are responsible for holding the axis labels (including a Data‐\n",
    "# Frame’s column names) and other metadata (like the axis name or names). Any array\n",
    "# or other sequence of labels you use when constructing a Series or DataFrame is\n",
    "# internally converted to an Index\n",
    "\n",
    "obj = pd.Series(np.arange(3), index=[\"a\", \"b\", \"c\"])\n",
    "index = obj.index\n",
    "print(index,'\\n')\n",
    "index[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index objects are immutable and thus can’t be modified by the user:\n",
    "\n",
    "index[1]='d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Immutability makes it safer to share Index objects among data structures\n",
    "\n",
    "labels = pd.Index(np.arange(3))\n",
    "print(labels,'\\n')\n",
    "\n",
    "obj2 = pd.Series([1.5, -2.5, 0], index=labels)\n",
    "print(obj2)\n",
    "\n",
    "obj2.index is labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition to being array-like, an Index also behaves like a fixed-size set\n",
    "\n",
    "print(frame3,'\\n')\n",
    "frame3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Ohio\" in frame3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2003 in frame3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike Python sets, a pandas Index can contain duplicate labels\n",
    "\n",
    "pd.Index([\"foo\", \"foo\", \"bar\", \"bar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Essential Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing\n",
    "\n",
    "reindex is a method to create a new object with the values rearranged to align with the new index\n",
    "\n",
    "Table 5-3. reindex function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=[\"d\", \"b\", \"a\", \"c\"])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling reindex on this Series rearranges the data according to the new index,\n",
    "# introducing missing values if any index values were not already present:\n",
    "\n",
    "obj2 = obj.reindex([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ordered data like time series, we may want to do some interpolation or filling of\n",
    "# values when reindexing.\n",
    "\n",
    "obj3 = pd.Series([\"blue\", \"purple\", \"yellow\"], index=[0, 2, 4])\n",
    "print(obj3,'\\n')\n",
    "obj3.reindex(np.arange(6), method=\"ffill\") # choose 'ffill' - forward filling method during reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With DataFrame, reindex can alter the (row) index, columns, or both. \n",
    "# When passed only a sequence, it reindexes the rows in the result\n",
    "\n",
    "frame = pd.DataFrame(np.arange(9).reshape((3, 3)),\n",
    "                     index=[\"a\", \"c\", \"d\"],\n",
    "                     columns=[\"Ohio\", \"Texas\", \"California\"])\n",
    "\n",
    "frame2 = frame.reindex(index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns can be reindexed with the columns keyword\n",
    "\n",
    "states = [\"Texas\", \"Utah\", \"California\"]\n",
    "frame.reindex(columns=states)\n",
    "\n",
    "# Because \"Ohio\" was not in states, the data for that column is dropped from the result.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to reindex a particular axis is to pass the new axis labels as a positional\n",
    "# argument and then specify the axis to reindex with the axis keyword\n",
    "\n",
    "frame.reindex(states, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also reindex by using the loc operator, and many users prefer to always do it this way.\n",
    "# works only if all of the new index labels already exist in the DataFrame (whereas reindex \n",
    "# will insert missing data for new labels):\n",
    "\n",
    "frame.loc[[\"a\", \"d\", \"c\"], [\"California\", \"Texas\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Entries from an Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping one or more entries from an axis is simple if we already have an index array or list \n",
    "\n",
    "obj = pd.Series(np.arange(5.), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "print(obj,'\\n')\n",
    "\n",
    "# drop the row indexed as 'c', if any\n",
    "new_obj = obj.drop(\"c\")\n",
    "print(new_obj,'\\n')\n",
    "\n",
    "\n",
    "# drop the rows indexed as 'c' or 'd', if any\n",
    "print(obj.drop([\"d\", \"c\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With DataFrame, index values can be deleted from either axis. \n",
    "# To illustrate this, we first create an example DataFrame:\n",
    "    \n",
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling drop with a sequence of labels will drop values from the row labels (axis 0):\n",
    "\n",
    "data.drop(index=[\"Colorado\", \"Ohio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Uue the columns keyword to drop labels from the columns\n",
    "\n",
    "data.drop(columns=[\"two\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also drop values from the columns by passing axis=1 (which is like NumPy):\n",
    "\n",
    "data.drop(\"two\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also drop values from the columns by passing axis=\"columns\":\n",
    "\n",
    "data.drop([\"two\", \"four\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, Selection, and Filtering\n",
    "\n",
    "Table 5-4. Indexing options with DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series indexing (obj[...]) works analogously to NumPy array indexing, except we\n",
    "# can use the Series’s index values instead of only integers\n",
    "\n",
    "obj = pd.Series(np.arange(4.), index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[\"b\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[2:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[[\"b\", \"a\", \"d\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[[1, 3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[obj < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While we can select data by label this way, the preferred way to select index values is\n",
    "# with the special loc operator\n",
    "\n",
    "obj.loc[[\"b\", \"a\", \"d\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason to prefer loc is because of the different treatment of integers when\n",
    "# indexing with []. Regular []-based indexing will treat integers as labels if the index\n",
    "# contains integers, so the behavior differs depending on the data type of the index.\n",
    "\n",
    "obj1 = pd.Series([1, 2, 3], index=[2, 0, 1])\n",
    "obj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n",
    "obj2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index contains integers, therefore, regular []-based indexing will treat integers as labels\n",
    "obj1[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using loc, the expression obj.loc[[0, 1, 2]] will fail when the index does not contain integers\n",
    "\n",
    "obj2.loc[[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since loc operator indexes exclusively with labels, there is also an iloc operator\n",
    "# that indexes exclusively with integers to work consistently whether or not the index\n",
    "# contains integers\n",
    "\n",
    "obj1.iloc[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.iloc[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also slice with labels, but it works differently from normal Python slicing \n",
    "# in that the endpoint is inclusive\n",
    "\n",
    "obj2.loc[\"b\":\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning values using these methods modifies the corresponding section of the Series:\n",
    "\n",
    "obj2.loc[\"b\":\"c\"] = 5\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing into a DataFrame retrieves one or more columns either with a single value or sequence:\n",
    "\n",
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"two\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"three\", \"one\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing\n",
    "\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting data with boolean array\n",
    "data[data[\"three\"] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce a boolean DataFrame with a scalar comparison\n",
    "\n",
    "data < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning values to locations where values are less than 5\n",
    "\n",
    "data[data < 5] = 0\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection on DataFrame with loc and iloc\n",
    "\n",
    "Like Series, DataFrame has special attributes **loc** and **iloc** for label-based and\n",
    "integer-based indexing, respectively. Since DataFrame is two-dimensional, you can\n",
    "select a subset of the rows and columns with NumPy-like notation using either axis\n",
    "labels (loc) or integers (iloc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the row labeled as \"Colorado\"\n",
    "data.loc[\"Colorado\"]\n",
    "\n",
    "#The result of selecting a single row is a Series with an index that contains the DataFrame’s column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To select multiple roles, creating a new DataFrame, pass a sequence of labels\n",
    "\n",
    "data.loc[[\"Colorado\", \"New York\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can combine both row and column selection in loc by separating the selections with a comma\n",
    "\n",
    "data.loc[\"Colorado\", [\"two\", \"three\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using iloc similarly\n",
    "\n",
    "data.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[[2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2, [3, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[[1, 2], [3, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both loc and iloc indexing functions work with slices in addition to single labels or lists of labels\n",
    "\n",
    "data.loc[:\"Utah\", \"two\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:, :3][data.three > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean arrays can be used with loc but not iloc\n",
    "data.loc[data.three >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integer indexing pitfalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with pandas objects indexed by integers can be a stumbling block for new\n",
    "# users since they work differently from built-in Python data structures like lists and\n",
    "# tuples. \n",
    "\n",
    "#For example, you might not expect the following code to generate an error\n",
    "\n",
    "ser = pd.Series(np.arange(3.))\n",
    "print(ser,'\\n')\n",
    "ser[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the other hand, with a noninteger index, there is no such ambiguity:\n",
    "\n",
    "ser2 = pd.Series(np.arange(3.), index=[\"a\", \"b\", \"c\"])\n",
    "print(ser2,'\\n')\n",
    "ser2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have an axis index containing integers, data selection will always be label\n",
    "#oriented. As I said above, if you use loc (for labels) or iloc (for integers) you will get\n",
    "#exactly what you want:\n",
    "\n",
    "ser.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing with integers is always integer oriented\n",
    "\n",
    "ser[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitfalls with chained indexing`\n",
    "\n",
    "indexing attributes can also be used to modify\n",
    "DataFrame objects in place, but doing so requires some care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, \"one\"] = 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2] = 5\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"four\"] > 5] = 3\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A common gotcha for new pandas users is to chain selections when assigning, like this:\n",
    "\n",
    "data.loc[data.three == 5][\"three\"] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic and Data Alignment\n",
    "\n",
    "pandas can make it much simpler to work with objects that have different indexes.\n",
    "\n",
    "Table 5-5. Flexible arithmetic methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, when we add objects, if any index pairs are not the same, the respective\n",
    "# index in the result will be the union of the index pairs\n",
    "\n",
    "s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=[\"a\", \"c\", \"d\", \"e\"])\n",
    "s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1],\n",
    "               index=[\"a\", \"c\", \"e\", \"f\", \"g\"])\n",
    "print(s1,'\\n')\n",
    "print(s2,'\\n')\n",
    "print(s1+s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the case of DataFrame, alignment is performed on both rows and columns\n",
    "\n",
    "df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list(\"bcd\"),\n",
    "                   index=[\"Ohio\", \"Texas\", \"Colorado\"])\n",
    "df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list(\"bde\"),\n",
    "                   index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "print(df1,'\\n')\n",
    "print(df2,'\\n')\n",
    "print(df1+df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"A\": [1, 2]})\n",
    "df2 = pd.DataFrame({\"B\": [3, 4]})\n",
    "print(df1,'\\n')\n",
    "print(df2,'\\n')\n",
    "print(df1+df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arithmetic methods with fill values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)),\n",
    "                   columns=list(\"abcd\"))\n",
    "df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)),\n",
    "                   columns=list(\"abcde\"))\n",
    "df2.loc[1, \"b\"] = np.nan\n",
    "#df1\n",
    "#df2\n",
    "print(df1,'\\n')\n",
    "print(df2,'\\n')\n",
    "print(df1+df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the add method on df1, I pass df2 and an argument to fill_value, which\n",
    "#substitutes the passed value for any missing values in the operation\n",
    "\n",
    "df1.add(df2, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Table 5-5 for a listing of Series and DataFrame methods for arithmetic. \n",
    "# Each has # a counterpart, starting with the letter r, that has arguments reversed. \n",
    "# So these two statements are equivalent:\n",
    "\n",
    "1 / df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rdiv(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when reindexing a Series or DataFrame, you can also specify a different fill value\n",
    "print(df1,'\\n')\n",
    "print(df2,'\\n')\n",
    "\n",
    "df1.reindex(columns=df2.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations between DataFrame and Series\n",
    "\n",
    "As with NumPy arrays of different dimensions, arithmetic between DataFrame and\n",
    "Series is also defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we subtract arr[0] from arr, the subtraction is performed once for each row.\n",
    "# This is referred to as broadcasting\n",
    "\n",
    "arr = np.arange(12.).reshape((3, 4))\n",
    "print(arr,'\\n')\n",
    "print(arr[0],'\\n')\n",
    "arr - arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(12.).reshape((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "series = frame.iloc[0]\n",
    "\n",
    "print(frame,'\\n')\n",
    "print(series,'\\n')\n",
    "print(frame-series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 = pd.Series(np.arange(3), index=[\"b\", \"e\", \"f\"])\n",
    "print(series2,'\\n')\n",
    "print(frame,'\\n')\n",
    "frame + series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to broadcast over the columns, matching on the rows, we have to\n",
    "#use one of the arithmetic methods and specify to match over the index.\n",
    "\n",
    "series3 = frame[\"d\"]\n",
    "\n",
    "print(frame,'\\n')\n",
    "print(series3,'\\n')\n",
    "\n",
    "frame.sub(series3, axis=\"index\") # subtract series3 from each column of frame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Application and Mapping\n",
    "\n",
    "NumPy ufuncs (element-wise array methods) also work with pandas objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.random.standard_normal((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "print(frame,'\\n')\n",
    "np.abs(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another frequent operation is applying a function on one-dimensional arrays to each\n",
    "#column or row. DataFrame’s apply method does exactly this:\n",
    "\n",
    "# In this example, the function f, which computes the difference between the maximum and\n",
    "# minimum of a Series, is invoked once on each column in frame. The result is a Series\n",
    "# having the columns of frame as its index\n",
    "\n",
    "def f1(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "frame.apply(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we pass axis=\"columns\" to apply, the function will be invoked once per row instead.\n",
    "\n",
    "frame.apply(f1, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function passed to apply need not return a scalar value; it can also return a Series with multiple values\n",
    "\n",
    "def f2(x):\n",
    "    return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n",
    "frame.apply(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise Python functions can be used, too. Suppose you wanted to compute\n",
    "# a formatted string from each floating-point value in frame. You can do this with\n",
    "# applymap:\n",
    "\n",
    "def my_format(x):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "frame.applymap(my_format)\n",
    "\n",
    "# The reason for the name applymap is that Series has a map method for applying an\n",
    "# element-wise function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[\"e\"].map(my_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort lexicographically by row or column label, use the sort_index method, which returns\n",
    "# a new, sorted object\n",
    "\n",
    "obj = pd.Series(np.arange(4), index=[\"d\", \"a\", \"b\", \"c\"])\n",
    "print(obj,'\\n')\n",
    "obj.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frame = pd.DataFrame(np.arange(8).reshape((2, 4)),\n",
    "                     index=[\"three\", \"one\"],\n",
    "                     columns=[\"d\", \"a\", \"b\", \"c\"])\n",
    "print(frame,'\\n')\n",
    "print(frame.sort_index(),'\\n')\n",
    "print(frame.sort_index(axis=\"columns\"),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is sorted in ascending order by default but can be sorted in descending order too:\n",
    "\n",
    "frame.sort_index(axis=\"columns\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sort_values method sort a Series by its values:\n",
    "\n",
    "obj = pd.Series([4, 7, -3, 2])\n",
    "obj.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any missing values are sorted to the end of the Series by default\n",
    "\n",
    "obj = pd.Series([4, np.nan, 7, np.nan, -3, 2])\n",
    "obj.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values can be sorted to the start instead by using the na_position option\n",
    "\n",
    "obj.sort_values(na_position=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When sorting a DataFrame, you can use the data in one or more columns as the sort keys. \n",
    "# To do so, pass one or more column names to sort_values\n",
    "\n",
    "# In this example, we sort rows by the value of column b\n",
    "\n",
    "frame = pd.DataFrame({\"b\": [4, 7, -3, 2], \"a\": [0, 1, 0, 1]})\n",
    "print(frame,'\\n')\n",
    "print(frame.sort_values(\"b\"),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, we sort rows by the values of a, and then by the values of b\n",
    "\n",
    "frame.sort_values([\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking\n",
    "\n",
    "Table 5-6. Tie-breaking methods with rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking assigns ranks from one through the number of valid data points in an array,\n",
    "# starting from the lowest value. The rank methods for Series and DataFrame are the\n",
    "# place to look; by default, rank breaks ties by assigning each group the mean rank\n",
    "\n",
    "obj = pd.Series([7, -5, 7, 4, 2, 0, 4])\n",
    "obj.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranks can also be assigned according to the order in which they’re observed in the data:\n",
    "obj.rank(method=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank in descending order\n",
    "\n",
    "obj.rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame can compute ranks over the rows or the columns\n",
    "\n",
    "frame = pd.DataFrame({\"b\": [4.3, 7, -3, 2], \"a\": [0, 1, 0, 1],\n",
    "                      \"c\": [-2, 5, 8, -2.5]})\n",
    "print(frame,'\\n')\n",
    "print(frame.rank(axis=\"columns\"),'\\n')\n",
    "print(frame.rank(axis=\"rows\"),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis Indexes with Duplicate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(5), index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data selection is one of the main things that behaves differently with duplicates.\n",
    "# Indexing a label with multiple entries returns a Series, while single entries return a\n",
    "# scalar value:\n",
    "    \n",
    "print(obj[\"a\"],'\\n')\n",
    "print(obj[\"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same logic extends to indexing rows (or columns) in a DataFrame\n",
    "\n",
    "df = pd.DataFrame(np.random.standard_normal((5, 3)),\n",
    "                  index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "print(df,'\\n')\n",
    "print(df.loc[\"b\"],'\\n')\n",
    "print(df.loc[\"c\"],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Summarizing and Computing Descriptive Statistics\n",
    "\n",
    "pandas objects are equipped with a set of common mathematical and statistical methods.\n",
    "Most of these fall into the category of reductions or summary statistics, methods\n",
    "that extract a single value (like the sum or mean) from a Series, or a Series of values\n",
    "from the rows or columns of a DataFrame. Compared with the similar methods\n",
    "found on NumPy arrays, they have built-in handling for missing data.\n",
    "\n",
    "Table 5-7 is a list of common options for each reduction method\n",
    "\n",
    "Table 5-8 is a full list of summary statistics and related methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dataframe with missing data\n",
    "\n",
    "df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\n",
    "                   [np.nan, np.nan], [0.75, -1.3]],\n",
    "                  index=[\"a\", \"b\", \"c\", \"d\"],\n",
    "                  columns=[\"one\", \"two\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling DataFrame’s sum method returns a Series containing column sums\n",
    "\n",
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing axis=\"columns\" or axis=1 sums across the columns instead:\n",
    "\n",
    "df.sum(axis=\"columns\")\n",
    "\n",
    "# When an entire row or column contains all NA values, the sum is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the skipna option can disable the default NaN processing method\n",
    "\n",
    "df.sum(axis=\"index\", skipna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=\"columns\", skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some aggregations, like mean, require at least one non-NA value to yield a value result\n",
    "# in this example, row 'c' is all NaN. Therefore, the mean cannot be calcualted, yielding a result of NaN\n",
    "\n",
    "df.mean(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxmin and idxmax, return indirect statistics, \n",
    "# like the index value where the minimum or maximum values are attained\n",
    "\n",
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some methods are cumulative, like sumsum\n",
    "\n",
    "df.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some methods are neither reductions nor accumulations. \n",
    "# describe is one such example, producing multiple summary statistics in one shot:\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On nonnumeric data, describe produces alternative summary statistics\n",
    "\n",
    "obj = pd.Series([\"a\", \"a\", \"b\", \"c\"] * 4)\n",
    "obj.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_pickle(\"examples/yahoo_price.pkl\")\n",
    "print(price)\n",
    "\n",
    "returns = price.pct_change() # call pct_change method to attain return (rate)\n",
    "returns.tail() # display the result of the last five \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between MSTF's return and IBM's return\n",
    "\n",
    "returns[\"MSFT\"].corr(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corvariance between MSTF's return and IBM's return\n",
    "\n",
    "returns[\"MSFT\"].cov(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame’s corr can return a full correlation matrix as a DataFrame\n",
    "\n",
    "returns.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame’s cov can return a full covariance matrix as a DataFrame\n",
    "\n",
    "returns.cov()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame’s corrwith method, you can compute pair-wise correlations \n",
    "# between a DataFrame’s columns or rows with another Series or DataFrame\n",
    "\n",
    "returns.corrwith(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing a DataFrame computes the correlations of matching column names\n",
    "# this example calculate the correlation between a company's stock raturn and its stock volume\n",
    "\n",
    "volume = pd.read_pickle(\"examples/yahoo_volume.pkl\")\n",
    "\n",
    "returns.corrwith(volume)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Values, Value Counts, and Membership\n",
    "\n",
    "Table 5-9 Unique, value counts, and set membership methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([\"c\", \"a\", \"d\", \"a\", \"c\", \"b\", \"b\", \"c\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unique method gives an array of unique values in a Series\n",
    "uniques = obj.unique()\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value_count method computes a Series containing value frequencies:\n",
    "\n",
    "obj.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Series is sorted by value in descending order as a convenience. value_counts is\n",
    "# also available as a top-level pandas method that can be used with NumPy arrays or\n",
    "# other Python sequences:\n",
    "\n",
    "pd.value_counts(obj.to_numpy(), sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isin performs a vectorized set membership check and can be useful in filtering a\n",
    "#dataset down to a subset of values in a Series or column in a DataFrame\n",
    "\n",
    "print(obj)\n",
    "\n",
    "mask = obj.isin([\"b\", \"c\"])\n",
    "print(mask)\n",
    "\n",
    "obj[mask] # extract elements that belong to the set {\"b\", \"c\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index.get_indexer method, which gives you an index array from an array of possibly nondistinct values into another array of distinct values\n",
    "\n",
    "to_match = pd.Series([\"c\", \"a\", \"b\", \"b\", \"c\", \"a\"])\n",
    "unique_vals = pd.Series([\"c\", \"b\", \"a\"])\n",
    "indices = pd.Index(unique_vals).get_indexer(to_match)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Qu1\": [1, 3, 4, 3, 4],\n",
    "                     \"Qu2\": [2, 3, 1, 2, 3],\n",
    "                     \"Qu3\": [1, 5, 2, 4, 4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the frequency for a single column:\n",
    "\n",
    "data[\"Qu1\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute this for all columns, pass pandas.value_counts to the DataFrame’s apply method\n",
    "\n",
    "result = data.apply(pd.value_counts).fillna(0)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is also a DataFrame.value_counts method, but it computes counts considering\n",
    "# each row of the DataFrame as a tuple to determine the number of occurrences of each\n",
    "# distinct row\n",
    "\n",
    "data = pd.DataFrame({\"a\": [1, 1, 1, 2, 2], \"b\": [0, 0, 1, 0, 0]})\n",
    "print(data)\n",
    "\n",
    "data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Chapter 4: Getting Started with Pandas",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "557.778px",
    "left": "117px",
    "top": "181.997px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
