{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Module 1: Data Understanding, Description, and Summary<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Get-to-Know-the-Dataset\" data-toc-modified-id=\"1.-Get-to-Know-the-Dataset-1\">1. Get to Know the Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Dataframe\" data-toc-modified-id=\"1.1-Dataframe-1.1\">1.1 Dataframe</a></span></li><li><span><a href=\"#1.2-Data-Modification\" data-toc-modified-id=\"1.2-Data-Modification-1.2\">1.2 Data Modification</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.2.1-Sorting\" data-toc-modified-id=\"1.2.1-Sorting-1.2.1\">1.2.1 Sorting</a></span></li><li><span><a href=\"#1.2.2-Filtering\" data-toc-modified-id=\"1.2.2-Filtering-1.2.2\">1.2.2 Filtering</a></span></li></ul></li></ul></li><li><span><a href=\"#2-Data-Distribution\" data-toc-modified-id=\"2-Data-Distribution-2\">2 Data Distribution</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Categorical-Data\" data-toc-modified-id=\"2.1-Categorical-Data-2.1\">2.1 Categorical Data</a></span></li><li><span><a href=\"#2.2-Numerical-Data\" data-toc-modified-id=\"2.2-Numerical-Data-2.2\">2.2 Numerical Data</a></span></li></ul></li><li><span><a href=\"#3.-Numerical-Data-Description\" data-toc-modified-id=\"3.-Numerical-Data-Description-3\">3. Numerical Data Description</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Measurements-of-Locations\" data-toc-modified-id=\"3.1-Measurements-of-Locations-3.1\">3.1 Measurements of Locations</a></span></li><li><span><a href=\"#3.2-Measurements-of-Variability\" data-toc-modified-id=\"3.2-Measurements-of-Variability-3.2\">3.2 Measurements of Variability</a></span></li><li><span><a href=\"#3.2-Measurements-of-Distribution\" data-toc-modified-id=\"3.2-Measurements-of-Distribution-3.3\">3.2 Measurements of Distribution</a></span></li><li><span><a href=\"#3.4-Measurements-of-Correlation\" data-toc-modified-id=\"3.4-Measurements-of-Correlation-3.4\">3.4 Measurements of Correlation</a></span></li></ul></li><li><span><a href=\"#4.-Grouping-&amp;-Aggregrating-Data\" data-toc-modified-id=\"4.-Grouping-&amp;-Aggregrating-Data-4\">4. Grouping &amp; Aggregrating Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1-Time-Series\" data-toc-modified-id=\"4.1-Time-Series-4.1\">4.1 Time Series</a></span></li><li><span><a href=\"#4.2-Aggregrate-Data-with-groupby\" data-toc-modified-id=\"4.2-Aggregrate-Data-with-groupby-4.2\">4.2 Aggregrate Data with groupby</a></span></li><li><span><a href=\"#4.3-Cross-Tabulation\" data-toc-modified-id=\"4.3-Cross-Tabulation-4.3\">4.3 Cross-Tabulation</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.3.1-Use-crosstab\" data-toc-modified-id=\"4.3.1-Use-crosstab-4.3.1\">4.3.1 Use crosstab</a></span></li><li><span><a href=\"#4.3.2-Use-pivot_table\" data-toc-modified-id=\"4.3.2-Use-pivot_table-4.3.2\">4.3.2 Use pivot_table</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19929,
     "status": "ok",
     "timestamp": 1695075422375,
     "user": {
      "displayName": "Ruwen Qin",
      "userId": "01885423067234457717"
     },
     "user_tz": 240
    },
    "id": "IwI_PxadRcW9",
    "outputId": "a5bb2462-c720-4085-ab77-85f080c5a3ab"
   },
   "outputs": [],
   "source": [
    "# If you use Colab Notebook, you can uncomment the following to mount your Google Drive to Colab\n",
    "# After that, your colab notebook can read/write files and data in your Google Drive\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1695075422376,
     "user": {
      "displayName": "Ruwen Qin",
      "userId": "01885423067234457717"
     },
     "user_tz": 240
    },
    "id": "PsIesNpkQnjr",
    "outputId": "6fe628b2-1231-4dc3-c4ae-9e8ec6d058f5"
   },
   "outputs": [],
   "source": [
    "# If you use Colab Notebook, please change the current directory to be the folder that you save \n",
    "# your Notebook and data folder for example, I save my Colab files and data in the following location\n",
    "\n",
    "#%cd /content/drive/MyDrive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries and modules, and define default setting for the notebook\n",
    "\n",
    "import numpy as np # a foundamental package for scientific computing https://numpy.org/\n",
    "#np.random.seed(12345)\n",
    "#np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "import pandas as pd # a library of data analysis, https://pandas.pydata.org/\n",
    "from pandas import Series, DataFrame # import modules into the local namespace if they are frequently used\n",
    "PREVIOUS_MAX_ROWS = pd.options.display.max_rows\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_colwidth = 80\n",
    "\n",
    "import matplotlib.pyplot as plt # a module for plotting, https://matplotlib.org/\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "\n",
    "#import seaborn as sns # a module for data visualization, https://seaborn.pydata.org/index.html\n",
    "\n",
    "\n",
    "# to display multiple outputs in one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDd0QFuzot-f"
   },
   "source": [
    "# 1. Get to Know the Dataset\n",
    "\n",
    "In this section, we would like to develop an initial understanding of the dataset \"NY_bicycle.csv\", originally from NYC Open Data:\n",
    "https://data.cityofnewyork.us/Transportation/Bicycle-Counts-for-East-River-Bridges-Historical-/gua4-p9wg/about_data\n",
    "\n",
    "This dataset was used to measure the utilization of bicycles for the transportation planning purpose. This dataset is daily counts of bicycles crossing into or out of Manhattan via one of the East River bridges excluding Bronx thruways and the non-bikeable Hudson River tunnels for 7 months.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mnm4tucf89me"
   },
   "source": [
    "## 1.1 Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested expertises:\n",
    "\n",
    "1. Read the data file NY_Bicycle.csv as a DataFrame [Hint: use pd.read_csv)\n",
    "2. Take a look at the first few rows of data [Hint: use .head( )]\n",
    "3. Do you see any column that is not meaningful? [Hint: column 0]. If you feel that column is not useful, you may delete it. [Hint: use del]\n",
    "4. What columns are there in the dataset? What are their datatype? [Hint: use .info() or .columns()]\n",
    "5. What is the name of column 4? [Hint: columns are an object. use columns[int] to check specific column name]\n",
    "6. What is the datatypes of the DataFrame NY_Bicycle? [Hint: use .dtypes]\n",
    "7. What is the datatype of the column \"Weather\"? \n",
    "8. What is the index object of this DataFrame? [Hint: use .index] \n",
    "9. Access values in column 3 [Hint: .values[]]\n",
    "10. Access values in row 2 [Hint: .values[]]\n",
    "11. Access the value in row 2 of column 3 [Hint: .values[]]\n",
    "12. Display \"Weather\", a column of the DataFrame, as a series [Hint: use .column[  ]]\n",
    "13. How to use .iloc[] method to access one datapoint or a slice of the data? Try to following: access column 3, row 2, row 2 in column 3, a segment consists of rows 2&3 in columns 3&4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySSy0PsD-ucJ"
   },
   "source": [
    "## 1.2 Data Modification\n",
    "\n",
    "Sorting and filtering are commonly used methods to modify data so that we can understand data conveniently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqf7h2O6YX7P"
   },
   "source": [
    "### 1.2.1 Sorting\n",
    "\n",
    "Sorting is about ordering observations in the DataFrame\n",
    "\n",
    "Suggested exercises\n",
    "1. Sort the DataFrame by column \"Total\" in a descending order (i.e., from largest value to smallest value). If there are any missing values, put them at the begining [Hint: use .sort_values]\n",
    "2. Sort the DataFrame by column \"Weather\" in reverse alphabetical order\n",
    "3. Save the sorted results in step 1 as a new DataFrame. Then sort it by index [Hint: use .sort_index()]\n",
    "4. Sort the DataFrame by values of multiple columns in the following sequence: \"High_Temp_F\", \"Low_Temp_F\", \"Total\". Save the result as a new DataFrame\n",
    "5. display only columns \"High_Temp_F\", \"Low_Temp_F\", and \"Total\" of the sorted DataFrame in step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kw52kPIMc2bK"
   },
   "source": [
    "### 1.2.2 Filtering\n",
    "\n",
    "Filtering is a method to select an interested segment/slice of the data frame.\n",
    "\n",
    "Suggested Exercises:\n",
    "\n",
    "1. Extract rows 3~5 in columns 6-9 [Hint: .iloc]\n",
    "2. Sort the DataFrame by \"Total\" in the descending order, review the sorting result, and then extract the segment that meets the criteron \"Total\">26,000\n",
    "3. extract the segment with the crition \"Total\" value >26,000\n",
    "4. extract columns 'Precipitation','High_Temp_F', and 'Low_Temp_F' whose \"Total\" value >26,000 [Hint: use .loc[])\n",
    "5. extract the column 'Precipitation' whose 'Weather' value is equal to T\n",
    "6. extract columns 'Low_Temp_F' and 'High_Temp_F' with 'Brooklyn_Bridge' >=3,000 and 'Day'= Wednesday. Sort values by both 'Low_Temp_F' and 'High_Temp_F' in that order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WS5v2FhBLu9b"
   },
   "source": [
    "# 2 Data Distribution\n",
    "\n",
    "Almost every column in the DataFrame has distributed values. Data distribution refers to the way data is distributed across different values. \n",
    "\n",
    "Suggested exercise:\n",
    "\n",
    "1. generate column-wise descriptive statistics [Hint: use the .describe() instance method]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cmrvv2YIIQ9M"
   },
   "source": [
    "## 2.1 Categorical Data\n",
    "\n",
    "For categorical data, we generate frequency distributions:\n",
    "- **Frequency distribution**: A summary of data that shows the count of observations in each of several non-overlapping classes. Typically referred to as bins, when dealing with distributions.\n",
    "- **Relative frequency distribution**: A tabular summary of data showing the relative frequency for each bin.\n",
    "\n",
    "Suggested Exercises:\n",
    "\n",
    "1. Count observations of each weather type to show the frequency distribution [Hint: .value_counts]. \n",
    "2. Then, show the relative frequency distribution. [Hint: value_counts has an argument named normalize]\n",
    "3. [Optional] Show frequency distributions of observations by \"Weather\" as histograms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXZP_xsbFof6"
   },
   "source": [
    "## 2.2 Numerical Data\n",
    "\n",
    "\n",
    "For numerical data, we divide the range of data into equally spaced bins that are muturally exclusive and collective inclusive. Then, we count the number of observations falling in each bin. \n",
    "\n",
    "Suggested exertises:\n",
    "1. Count the number of observations in the Series \"Total\"\n",
    "2. Find the minimum and maximum values of \"Total\", respectively\n",
    "2. divide the data range of \"Total\" into 9 bins, and count the observations within each bin. [Hint: use pandas.cut]\n",
    "4. [Optional] Plot the histogram of \"Total\" to show the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKT1QpMwIDPD"
   },
   "source": [
    "# 3. Numerical Data Description\n",
    "\n",
    "For numerical data, descriptive statistics tell the center, spread, and shape of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqQHjYKiDw7S"
   },
   "source": [
    "## 3.1 Measurements of Locations\n",
    "\n",
    "Mean, median, and modes are common statistics describing the locations of data distributions.\n",
    "\n",
    "Suggested exercise:\n",
    "1. Calculate the mean value of the Series \"Total\"\n",
    "2. Calcualte the median value of \"Total\"\n",
    "3. Calculate the mode of \"Total\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib8Yp6OxETmb"
   },
   "source": [
    "## 3.2 Measurements of Variability\n",
    "\n",
    "Range, variance, standard deviation are commonly used statistics describing the variability/spread of data\n",
    "Suggested Exercises:\n",
    "1. Calculate the range of \"Total\"\n",
    "2. Calculate the variance of \"Total\"\n",
    "3. Calculate the standard deviation of \"Total\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NU3AAlZlnRG8"
   },
   "source": [
    "## 3.2 Measurements of Distribution\n",
    "\n",
    "quantiles and quartiles describe the data distribution\n",
    "\n",
    "1. Calculate 0.25, 0.5, and 0.75 quantiles\n",
    "2. What is the 0.99 quantile?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2g0ejmUIu7v"
   },
   "source": [
    "## 3.4 Measurements of Correlation\n",
    "\n",
    "Correlation coefficient and covariance between any two numerical variables can be calculated\n",
    "\n",
    "Suggested exercises:\n",
    "1. calculate the correlation between any two numerical Series [Hint: use .corr(numerical_only=True)]\n",
    "2. calcualte the correlation between the Series \"Brooklyn_Bridge\" and the Series \"Manhattan_Bridge\"\n",
    "3. calculate the covariance between any two numerical Series [Hint: use .corr(numerical_only=True)]\n",
    "4. calcualte the covariance between the Series \"Brooklyn_Bridge\" and the Series \"Manhattan_Bridge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQT2FK6fSw5G"
   },
   "source": [
    "# 4. Grouping & Aggregrating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Time Series\n",
    "\n",
    "If the dataset contains records collected overtime, it is helpful to formulate the data as time series data. In the dataset NY_bicycle. One column is a string Series named \"Date\", and another column is also a string Series named \"Day\". We can convert \"Date\" to DateTime Series, and convert \"Day\" to ordered categorical variable. Thereby, we can take advantages of methods and tools developed for time series data.\n",
    "\n",
    "Suggested Exercise:\n",
    "1. Convert the DataFrame NY_bicycle into a a time series dataset by creating a new DataFrame (name it as NY_bicycle_ts) whose index is a DateTimeIndex object with values equal to 'Date' in the DataFrame NY_bicycle.[Hint: pandas.to_datetime, and .set_index can be considered]\n",
    "2. Convert the string Series \"Day\" of NY_bicycle_ts into ordered categorical variable [Hint: set up arguments in pandas.Categorical()] \n",
    "3. Can you count bicycles by \"Day\"? Please format the counts as comma separated integers (e.g., 42,421). What does your result look like if you skipped step 2?\n",
    "4. Can you count bicycles by months? Please format the counts as comma separated integers. [Hint: downsampling to monthly data using the resample method]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Aggregrate Data with groupby\n",
    "\n",
    "The instance method groupby allows dividing the dataset by one or more attributes. After that, we can aggregrate the data within each segment using descriptive statistics.\n",
    "\n",
    "Suggested Exercises:\n",
    "1. aggregate daily counts of bicycles to become total counts by 'Weather\", and name the aggregrated value as \"Total Count\". Please format the counts as comma-separated integers. \n",
    "2. repeat step 1 but sort values in the ascending order \n",
    "3. group data by \"Weather\", and output the key and size of each subgroup [Hint: key and data of each subgroup are part of the output object]\n",
    "4. aggregrate daily counts of bicycles to become total counts by \"Weather\" and \"Day\". Please format the counts as comma-separated integers. \n",
    "5. Unstack the result in step 4 by changing \"Weather\" from index to column [Hint: use unstack(level=). In order to use unstack, convert \"Weather\" and \"Day\" to index]\n",
    "6. group data by \"Weather\" and \"Day\". Then, calculate the following descriptive statistics of \"Total\" for each subgroup: mean, standard deviation, minimum, maximum, median. Keep 1 digit after the decimal point.\n",
    "7. reset the index for the output from step 6. What changes do you observe?\n",
    "8. [Optional] group data by \"Day\", then aggregrate Weather data in each subgroup as a string. For example, if a subgroup has five data points with \"Weather\" being 'N', 'N', 'R','N', 'T', the string is 'N,N,R,N,T'. [Hint: consider the join method]\n",
    "9. [Optional] group data by \"Weather\", then aggregrate Day data in each subgroup as a list.\n",
    "10. group data by \"Day\" and then determine the unique types of weather occured on each day of week. [Hint: use nunique() method)\n",
    "11. group data by \"Weather\" and aggregrate data as the sum of \"Total\". Plot a bar chart to show the aggregrated result. What's your observation? [Hint, result.plot()]\n",
    "13. \n",
    "12. group data by \"Day\" and aggregrate data by the sum of \"Total\". plot a line chart to show the aggregrated result. What's your observation?\n",
    "14. group data by \"Weather\". For each subgroup, aggregrate \"Total\" as mean and \"Precipitation\" as stdandard deviation\n",
    "15. group data by \"Weather\", and then get the subgroup with \"Weather\"=='T'\n",
    "16. group data by \"Weather\" and then generate a random sample of size 3 from each of the subgroup. [Hint: .sample(sample size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqNzXNGQHs5b"
   },
   "source": [
    "## 4.3 Cross-Tabulation\n",
    "\n",
    "Crosstabulation is a useful type of table for describing data of two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Use crosstab\n",
    "\n",
    "\n",
    "Suggested Exercises:\n",
    "1. Create a crosstabulation: \"Weather\" is the index, \"Day\" is the column, \"Total\" is the value, and mean is the method to aggregate value. Margins of the table are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Use pivot_table\n",
    "\n",
    "pivot_table is another pandas function for generating cross tabulation.\n",
    "\n",
    "Suggested Exercises:\n",
    "1. create a pivot table to summary data on two-axes using pd.pivot_table(DataFrame, values, index,colums,values,aggfunc,margins).  \"Weather\" is the index, \"Day\" is the column, \"Total\" is the value, and mean is the method to aggregate value. Margins of the table are needed.\n",
    "2. create a pivot table to summarize the mean values of \"Brooklyn_Bridge\" and \"Total\" by \"Weather\" and \"Day\". That is: Index is \"Weather\", Columns is \"Day\", Values are \"Brooklyn_Bridge\" and \"Total\", and aggfunc is numpy.mean. [Hint: pass a dictionary to aggfunc. The discdtionary specifies what function is used for aggregrating what values]\n",
    "3. create a pivot table to summarize the mean and standard deviation of \"Total\" by  \"Weather\" and \"Day\". That is: Index is \"Weather\", Columns is \"Day\", Values are \"Total\", and aggfunc are numpy.mean and numpy.std. [Hint: pass a list of functions to aggfunc]\n",
    "4. reate a table summarizing the mean values of \"High_Temp_F\" and \"Low_Temp_F\" when Weather is 'T'. [Hint: ceate a pivot table with two indices: \"Weather\" and \"Day\". Values are \"High_Temp_F\" and \"Low_Temp_F\". Aggfunc is mean. Then, get the slice with \"Weather\"=='T' using DataFrame.query()]\n",
    "5. reate a table summarizing the mean values of \"High_Temp_F\" and \"Low_Temp_F\" on Friday and when Weather is 'N' and 'R', respectively.[Hint: create a pivot table with two indices: \"Weather\" and \"Day\". Values are \"High_Temp_F\" and \"Low_Temp_F\". Aggfunc is mean. Then, get the slice with \"Weather\"=='N' or 'R' and \"Day\"=='Friday']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNUwTx0Vw95nMIPPNWqgAoW",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Module 1: Data Understanding, Description, and Summary",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "557.778px",
    "left": "597px",
    "top": "110.113px",
    "width": "216.884px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
